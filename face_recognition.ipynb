{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read_data from dataset\n",
    "\n",
    "- convert images to gray scale\n",
    "\n",
    "- convert each image to a vector of 10304 value\n",
    "\n",
    "- stack 400 vector into a single data matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = \"dataset\\\\s%d\\\\%d.pgm\"\n",
    "\n",
    "def read_data (): \n",
    "\n",
    "    data_matrix = np.empty((0, 10304))  \n",
    "    label_vector = np.array([])\n",
    "    for folder_counter in range (1, 5):\n",
    "        for image_counter in range (1, 11):\n",
    "            image = cv2.imread(path%(folder_counter,image_counter))\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            flattened_image = gray_image.flatten()\n",
    "            flattened_image = np.array(flattened_image)\n",
    "            data_matrix = np.append(data_matrix, [flattened_image], axis=0)\n",
    "            label_vector = np.append(label_vector, folder_counter)\n",
    "            # data_matrix = np.vstack((data_matrix, flattened_image))\n",
    "    \n",
    "    print(data_matrix.shape)\n",
    "\n",
    "    return data_matrix, label_vector\n",
    "\n",
    "\n",
    "dm, lv = read_data()\n",
    "print(lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data to training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_data(data_matrix, label_vector):\n",
    "    \n",
    "    test_data = data_matrix[::2] #even  \n",
    "    training_data = data_matrix[1::2] #odd\n",
    "\n",
    "    test_labels = label_vector[::2]\n",
    "    training_labels = label_vector[1::2] \n",
    "\n",
    "    return test_data, training_data, training_labels, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PCA(training_data, alpha):\n",
    "\n",
    "    mean_vector = np.mean(training_data, axis=0)\n",
    "   \n",
    "    centered_training_data = training_data - mean_vector\n",
    "   \n",
    "    covariance_matrix = np.cov(np.transpose(centered_training_data), bias= True)\n",
    "   \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "   \n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "   \n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "\n",
    "    accum = sorted_eigenvalues[0]\n",
    "  \n",
    "    sum = np.sum(sorted_eigenvalues)\n",
    "  \n",
    "    i = 1\n",
    "   \n",
    "    while( accum / sum < alpha):\n",
    "        accum+=sorted_eigenvalues[i]\n",
    "        i+=1\n",
    "\n",
    "    projection_matrix = eigenvectors[:, sorted_indices][:, :i]\n",
    "  \n",
    "    reduced_dimensionality_data = np.transpose(projection_matrix).dot(np.transpose(centered_training_data))\n",
    "\n",
    "    return np.transpose(reduced_dimensionality_data), projection_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 10304)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "training_data, test_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = PCA(training_data, 0.91)\n",
    "\n",
    "print(\"after PCA\")\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "\n",
    "print(\"after reducing test data\")\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_classifier.fit(reduced_dimensionality_data, training_labels)\n",
    "\n",
    "print(\"after fit\")\n",
    "\n",
    "test_pred = knn_classifier.predict(reduced_dimensionality_test_data)\n",
    "\n",
    "print(\"after prediction\")\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
