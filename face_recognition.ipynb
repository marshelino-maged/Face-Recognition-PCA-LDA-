{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read_data from dataset\n",
    "\n",
    "- convert images to gray scale\n",
    "\n",
    "- convert each image to a vector of 10304 value\n",
    "\n",
    "- stack 400 vector into a single data matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10304)\n",
      "(10, 10304)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def process_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    flattened_image = gray_image.flatten()\n",
    "    flattened_image = np.array(flattened_image)\n",
    "    return flattened_image\n",
    "\n",
    "def read_data (no_of_folders, no_of_images): \n",
    "\n",
    "    path = \"dataset\\\\s%d\\\\%d.pgm\"\n",
    "\n",
    "    data_matrix = np.empty((0, 10304))  \n",
    "    label_vector = np.array([])\n",
    "\n",
    "    for folder_counter in range (1, no_of_folders + 1):\n",
    "        for image_counter in range (1, no_of_images + 1):\n",
    "            processed_image = process_image(path%(folder_counter,image_counter))\n",
    "            data_matrix = np.append(data_matrix, [processed_image], axis=0)\n",
    "            label_vector = np.append(label_vector, folder_counter)\n",
    "    \n",
    "    print(data_matrix.shape)\n",
    "\n",
    "    return data_matrix, label_vector\n",
    "\n",
    "\n",
    "def read_nonfaces(no_of_images):\n",
    "\n",
    "    path= \"processed_nonfaces_dataset\\\\%d.jpg\"\n",
    "    data_matrix = np.empty((0, 10304))  \n",
    "\n",
    "    for i in range (1, no_of_images + 1):\n",
    "\n",
    "        processed_image = process_image(path%(i))\n",
    "        data_matrix = np.append(data_matrix, [processed_image], axis=0)\n",
    "\n",
    "    return data_matrix\n",
    "\n",
    "\n",
    "\n",
    "dm, lv = read_data( 40, 10)\n",
    "\n",
    "dm2 = read_nonfaces(10)\n",
    "\n",
    "print(dm2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data to training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_data(data_matrix, label_vector):\n",
    "    \n",
    "    test_data = data_matrix[::2] #even  \n",
    "    training_data = data_matrix[1::2] #odd\n",
    "\n",
    "    test_labels = label_vector[::2]\n",
    "    training_labels = label_vector[1::2] \n",
    "\n",
    "    return test_data, training_data, training_labels, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PCA(training_data, alpha):\n",
    "\n",
    "    mean_vector = np.mean(training_data, axis=0)\n",
    "   \n",
    "    centered_training_data = training_data - mean_vector\n",
    "\n",
    "    covariance_matrix = np.cov(np.transpose(centered_training_data), bias= True)\n",
    "   \n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "   \n",
    "\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "   \n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    accum = sorted_eigenvalues[0]\n",
    "  \n",
    "    sum = np.sum(sorted_eigenvalues)\n",
    "  \n",
    "    i = 1\n",
    "   \n",
    "    while( accum / sum < alpha):\n",
    "        accum+=sorted_eigenvalues[i]\n",
    "        i+=1\n",
    "\n",
    "    projection_matrix = sorted_eigenvectors[:, :i]\n",
    "  \n",
    "    print(\"multiplying the two matrices\")\n",
    "    reduced_dimensionality_data = np.transpose(projection_matrix).dot(np.transpose(training_data))\n",
    "\n",
    "    return np.transpose(reduced_dimensionality_data), projection_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10304)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'split_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      4\u001b[0m data_matrix, label_vector \u001b[38;5;241m=\u001b[39m read_data()\n\u001b[1;32m----> 6\u001b[0m test_data, training_data, training_labels, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43msplit_data\u001b[49m(data_matrix, label_vector)\n\u001b[0;32m      8\u001b[0m reduced_dimensionality_data, projection_matrix \u001b[38;5;241m=\u001b[39m PCA(training_data, \u001b[38;5;241m0.95\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter PCA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = PCA(training_data, 0.95)\n",
    "\n",
    "print(\"after PCA\")\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "reduced_dimensionality_test_data = np.transpose(reduced_dimensionality_test_data)\n",
    "\n",
    "\n",
    "print(\"after reducing test data\")\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_classifier.fit(reduced_dimensionality_data, training_labels)\n",
    "\n",
    "print(\"after fit\")\n",
    "\n",
    "test_pred = knn_classifier.predict(reduced_dimensionality_test_data)\n",
    "\n",
    "print(\"after prediction\")\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for every value of alpha using PCA.\n",
    "\n",
    "as we see when alpha increase the accuracy increases.\n",
    "\n",
    "but for alpha = 0.95 the accuracy decreases due to some reasons:\n",
    "- Overfitting: many components might be including noise or irrelevant details from the data that can lead to overfitting\n",
    "- Curse of dimensionality: when you have many features data becomes sparse and distances between points become less meaningful\n",
    "- Not all variance is useful: PCA tries to keep the components that explain the most variance, but not all variance is useful for classification.\n",
    "\n",
    "|  Alpha   | Accuracy |\n",
    "| -------- | -------- |\n",
    "| 0.8      | 0.93     |\n",
    "| 0.85     | 0.94     |\n",
    "| 0.9      | 0.945    |\n",
    "| 0.95     | 0.935    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "2 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 4.46966918],\n",
       "        [ 3.48662485],\n",
       "        [ 3.06936143],\n",
       "        [ 5.22993727],\n",
       "        [ 5.30419602],\n",
       "        [12.35170446],\n",
       "        [ 8.79082087],\n",
       "        [10.26538736],\n",
       "        [10.19112861],\n",
       "        [12.4259632 ]]),\n",
       " array([[0.90878558],\n",
       "        [0.41726342]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sc\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def LDA(training_data, training_labels):\n",
    "\n",
    "    unique_values, counts = np.unique(training_labels, return_counts=True)\n",
    "    \n",
    "\n",
    "    mean_vector = np.mean(training_data, axis=0)\n",
    "    sb=0\n",
    "    s=0\n",
    "    for i in range(unique_values.shape[0]):\n",
    "        print(unique_values[i], counts[i])\n",
    "        class_i=training_data[np.where(training_labels==unique_values[i])]\n",
    "        class_mean_i = np.mean(class_i,axis=0)\n",
    "\n",
    "        sb+=counts[i]*np.outer(class_mean_i-mean_vector,class_mean_i-mean_vector)\n",
    "        z =class_i - class_mean_i\n",
    "        s+= np.transpose(z).dot(z)\n",
    "\n",
    "    # print(s)\n",
    "    # print('-------------sb--------------')\n",
    "    # print(sb)\n",
    "    # print('-----------s-1 sb----------------')\n",
    "    # print(np.linalg.inv(s).dot(sb))\n",
    "    # print('-----------eigen values----------------')\n",
    "    \n",
    "\n",
    "    eigenvalues, eigenvectors = sc.linalg.eig(np.linalg.inv(s).dot(sb))\n",
    "\n",
    "\n",
    "    # print(eigenvalues)\n",
    "    # print('------------eigen vectors---------------')\n",
    "    # print(eigenvectors)\n",
    "\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    projection_matrix = sorted_eigenvectors[:, :unique_values.shape[0]-1]\n",
    "    projection_matrix = np.real(projection_matrix)\n",
    "    # print('-----------projection matrix----------------')\n",
    "    # print (projection_matrix)\n",
    "\n",
    "    reduced_dimensionality_data = np.transpose(projection_matrix).dot(np.transpose(training_data))\n",
    "\n",
    "    # print('------------result---------------')\n",
    "    # print (np.transpose(reduced_dimensionality_data))\n",
    "\n",
    "    return np.transpose(reduced_dimensionality_data), projection_matrix\n",
    "\n",
    "\n",
    "\n",
    "training_data = np.array([[4,2], [2,4], [2,3], [3,6], [4,4], [9,10], [6,8], [9,5], [8,7], [10,8]])\n",
    "training_labels = np.array([1,1,1,1,1,2,2,2,2,2])\n",
    "LDA(training_data, training_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10304)\n",
      "Accuracy: 0.935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = LDA(training_data)\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "reduced_dimensionality_test_data = np.transpose(reduced_dimensionality_test_data)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_classifier.fit(reduced_dimensionality_data, training_labels)\n",
    "\n",
    "test_pred = knn_classifier.predict(reduced_dimensionality_test_data)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_k(reduced_dimensionality_data,training_labels,reduced_dimensionality_test_data,test_labels,k):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn_classifier.fit(reduced_dimensionality_data, training_labels)\n",
    "\n",
    "    test_pred = knn_classifier.predict(reduced_dimensionality_test_data)\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA with k=1,3,5,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = LDA(training_data)\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "reduced_dimensionality_test_data = np.transpose(reduced_dimensionality_test_data)\n",
    "\n",
    "LDA_performance_with_recpect_to_k = []\n",
    "for i in range (1,8,2):\n",
    "    LDA_performance_with_recpect_to_k.append(test_with_k(reduced_dimensionality_data,training_labels,reduced_dimensionality_test_data,test_labels,i))\n",
    "    \n",
    "plt.plot(list(range(1,8,2)), LDA_performance_with_recpect_to_k , marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.title('2D Data Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA with k=1,3,5,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = PCA(training_data)\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "reduced_dimensionality_test_data = np.transpose(reduced_dimensionality_test_data)\n",
    "\n",
    "PCA_performance_with_recpect_to_k = []\n",
    "for i in range (1,8,2):\n",
    "    LDA_performance_with_recpect_to_k.append(test_with_k(reduced_dimensionality_data,training_labels,reduced_dimensionality_test_data,test_labels,i))\n",
    "    \n",
    "plt.plot(list(range(1,8,2)), LDA_performance_with_recpect_to_k , marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.title('2D Data Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
