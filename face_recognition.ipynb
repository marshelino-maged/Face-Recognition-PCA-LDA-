{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read_data from dataset\n",
    "\n",
    "- convert images to gray scale\n",
    "\n",
    "- convert each image to a vector of 10304 value\n",
    "\n",
    "- stack 400 vector into a single data matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10304)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 11. 11. 11. 11. 11. 11. 11. 11.\n",
      " 11. 11. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 13. 13. 13. 13. 13. 13.\n",
      " 13. 13. 13. 13. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 17. 17.\n",
      " 17. 17. 17. 17. 17. 17. 17. 17. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 20. 20. 20. 20. 20. 20. 20. 20.\n",
      " 20. 20. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 22. 22. 22. 22. 22. 22.\n",
      " 22. 22. 22. 22. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 24. 24. 24. 24.\n",
      " 24. 24. 24. 24. 24. 24. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25. 26. 26.\n",
      " 26. 26. 26. 26. 26. 26. 26. 26. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27.\n",
      " 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 29. 29. 29. 29. 29. 29. 29. 29.\n",
      " 29. 29. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 31. 31. 31. 31. 31. 31.\n",
      " 31. 31. 31. 31. 32. 32. 32. 32. 32. 32. 32. 32. 32. 32. 33. 33. 33. 33.\n",
      " 33. 33. 33. 33. 33. 33. 34. 34. 34. 34. 34. 34. 34. 34. 34. 34. 35. 35.\n",
      " 35. 35. 35. 35. 35. 35. 35. 35. 36. 36. 36. 36. 36. 36. 36. 36. 36. 36.\n",
      " 37. 37. 37. 37. 37. 37. 37. 37. 37. 37. 38. 38. 38. 38. 38. 38. 38. 38.\n",
      " 38. 38. 39. 39. 39. 39. 39. 39. 39. 39. 39. 39. 40. 40. 40. 40. 40. 40.\n",
      " 40. 40. 40. 40.]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = \"dataset\\\\s%d\\\\%d.pgm\"\n",
    "\n",
    "def read_data (): \n",
    "\n",
    "    data_matrix = np.empty((0, 10304))  \n",
    "    label_vector = np.array([])\n",
    "    for folder_counter in range (1, 41):\n",
    "        for image_counter in range (1, 11):\n",
    "            image = cv2.imread(path%(folder_counter,image_counter))\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            flattened_image = gray_image.flatten()\n",
    "            flattened_image = np.array(flattened_image)\n",
    "            data_matrix = np.append(data_matrix, [flattened_image], axis=0)\n",
    "            label_vector = np.append(label_vector, folder_counter)\n",
    "            # data_matrix = np.vstack((data_matrix, flattened_image))\n",
    "    \n",
    "    print(data_matrix.shape)\n",
    "\n",
    "    return data_matrix, label_vector\n",
    "\n",
    "\n",
    "dm, lv = read_data()\n",
    "print(lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data to training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_data(data_matrix, label_vector):\n",
    "    \n",
    "    test_data = data_matrix[::2] #even  \n",
    "    training_data = data_matrix[1::2] #odd\n",
    "\n",
    "    test_labels = label_vector[::2]\n",
    "    training_labels = label_vector[1::2] \n",
    "\n",
    "    return test_data, training_data, training_labels, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PCA(training_data, alpha):\n",
    "\n",
    "    mean_vector = np.mean(training_data, axis=0)\n",
    "   \n",
    "    centered_training_data = training_data - mean_vector\n",
    "\n",
    "    covariance_matrix = np.cov(np.transpose(centered_training_data), bias= True)\n",
    "   \n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "   \n",
    "\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "   \n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    accum = sorted_eigenvalues[0]\n",
    "  \n",
    "    sum = np.sum(sorted_eigenvalues)\n",
    "  \n",
    "    i = 1\n",
    "   \n",
    "    while( accum / sum < alpha):\n",
    "        accum+=sorted_eigenvalues[i]\n",
    "        i+=1\n",
    "\n",
    "    projection_matrix = sorted_eigenvectors[:, :i]\n",
    "  \n",
    "    print(\"multiplying the two matrices\")\n",
    "    reduced_dimensionality_data = np.transpose(projection_matrix).dot(np.transpose(training_data))\n",
    "\n",
    "    return np.transpose(reduced_dimensionality_data), projection_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10304)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'split_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      4\u001b[0m data_matrix, label_vector \u001b[38;5;241m=\u001b[39m read_data()\n\u001b[1;32m----> 6\u001b[0m test_data, training_data, training_labels, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43msplit_data\u001b[49m(data_matrix, label_vector)\n\u001b[0;32m      8\u001b[0m reduced_dimensionality_data, projection_matrix \u001b[38;5;241m=\u001b[39m PCA(training_data, \u001b[38;5;241m0.95\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter PCA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = PCA(training_data, 0.95)\n",
    "\n",
    "print(\"after PCA\")\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "reduced_dimensionality_test_data = np.transpose(reduced_dimensionality_test_data)\n",
    "\n",
    "\n",
    "print(\"after reducing test data\")\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_classifier.fit(reduced_dimensionality_data, training_labels)\n",
    "\n",
    "print(\"after fit\")\n",
    "\n",
    "test_pred = knn_classifier.predict(reduced_dimensionality_test_data)\n",
    "\n",
    "print(\"after prediction\")\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for every value of alpha using PCA.\n",
    "\n",
    "as we see when alpha increase the accuracy increases.\n",
    "\n",
    "but for alpha = 0.95 the accuracy decreases due to some reasons:\n",
    "- Overfitting: many components might be including noise or irrelevant details from the data that can lead to overfitting\n",
    "- Curse of dimensionality: when you have many features data becomes sparse and distances between points become less meaningful\n",
    "- Not all variance is useful: PCA tries to keep the components that explain the most variance, but not all variance is useful for classification.\n",
    "\n",
    "|  Alpha   | Accuracy |\n",
    "| -------- | -------- |\n",
    "| 0.8      | 0.93     |\n",
    "| 0.85     | 0.94     |\n",
    "| 0.9      | 0.945    |\n",
    "| 0.95     | 0.935    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10304)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def LDA(training_data):\n",
    "    \n",
    "    \n",
    "    mean_vector = np.mean(training_data, axis=0)\n",
    "    sb=0\n",
    "    s=0\n",
    "    for i in range (0, 40):\n",
    "        class_i=training_data[i*5:i*5+5]\n",
    "        class_mean_i = np.mean(class_i,axis=0)\n",
    "        sb+=5*np.outer(class_mean_i-mean_vector,class_mean_i-mean_vector)\n",
    "        z =class_i - class_mean_i\n",
    "        s+= np.transpose(z).dot(z)\n",
    "        \n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(np.linalg.inv(s).dot(sb))\n",
    "    \n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    projection_matrix = sorted_eigenvectors[:, :39]\n",
    "    \n",
    "    reduced_dimensionality_data = np.transpose(projection_matrix).dot(np.transpose(training_data))\n",
    "\n",
    "    return np.transpose(reduced_dimensionality_data), projection_matrix\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector) \n",
    "LDA(training_data)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10304)\n",
      "Accuracy: 0.935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = LDA(training_data)\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "reduced_dimensionality_test_data = np.transpose(reduced_dimensionality_test_data)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_classifier.fit(reduced_dimensionality_data, training_labels)\n",
    "\n",
    "test_pred = knn_classifier.predict(reduced_dimensionality_test_data)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_k(reduced_dimensionality_data,training_labels,reduced_dimensionality_test_data,test_labels,k):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn_classifier.fit(reduced_dimensionality_data, training_labels)\n",
    "\n",
    "    test_pred = knn_classifier.predict(reduced_dimensionality_test_data)\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA with k=1,3,5,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = LDA(training_data)\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "reduced_dimensionality_test_data = np.transpose(reduced_dimensionality_test_data)\n",
    "\n",
    "LDA_performance_with_recpect_to_k = []\n",
    "for i in range (1,8,2):\n",
    "    LDA_performance_with_recpect_to_k.append(test_with_k(reduced_dimensionality_data,training_labels,reduced_dimensionality_test_data,test_labels,i))\n",
    "    \n",
    "plt.plot(list(range(1,8,2)), LDA_performance_with_recpect_to_k , marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.title('2D Data Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA with k=1,3,5,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_matrix, label_vector = read_data()\n",
    "\n",
    "test_data, training_data, training_labels, test_labels = split_data(data_matrix, label_vector)\n",
    "\n",
    "reduced_dimensionality_data, projection_matrix = PCA(training_data)\n",
    "\n",
    "reduced_dimensionality_test_data = np.transpose(projection_matrix).dot(np.transpose(test_data))\n",
    "reduced_dimensionality_test_data = np.transpose(reduced_dimensionality_test_data)\n",
    "\n",
    "PCA_performance_with_recpect_to_k = []\n",
    "for i in range (1,8,2):\n",
    "    LDA_performance_with_recpect_to_k.append(test_with_k(reduced_dimensionality_data,training_labels,reduced_dimensionality_test_data,test_labels,i))\n",
    "    \n",
    "plt.plot(list(range(1,8,2)), LDA_performance_with_recpect_to_k , marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.title('2D Data Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
